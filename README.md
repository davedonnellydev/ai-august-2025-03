# Project 03 #AIAugustAppADay: Smart Recipe Finder

![Last Commit](https://img.shields.io/github/last-commit/davedonnellydev/ai-august-2025-03)  

**📆 Date**: 05/Aug/2025  
**🎯 Project Objective**: Enter ingredients, get suggested recipes generated by AI.   
**🚀 Features**: Enter or select ingredients; AI interprets ingredients & makes call to food API; Food API brings back recipes; Display recipe cards. Stretch goals: Change amounts based on serving sizes; Toggle between Metric & Imperial; Export/Share recipes  
**🛠️ Tech used**: Next.js, TypeScript, OpenAI API, [https://spoonacular.com/food-api](https://spoonacular.com/food-api)  
**▶️ Live Demo**: [https://dave-donnelly-ai-august-03.netlify.app/](https://dave-donnelly-ai-august-03.netlify.app/)  

## 🗒️ Summary

A day broken up by interruptions and distractions, I didn't get as far as I wanted with this one. You can take a look at the original plan here: [ai-august-2025-03.drawio.png](./ai-august-2025-03.drawio.png). You can see that the main functionality around the view of each single recipe is not there. I was fast running out of time this afternoon and once I got the API call working, I realised that the recipe data came with a 'source url' so I stuck that in there as a link out to the original recipe, so that at least users can get to the recipe details themselves! It was a lucky break, but not an ideal solution.

**Blockers**  
I was pretty confident that AI could build the components I needed for the app. I still wasn't sure how the two APIs would work together. I first tried to use AI to get the connection built but it overcomplicated things and made a bit of a mess. After that I had to spend the majority of my time flipping back and forth between the Spoonacular API documentation and a different section of the OpenAI API documentation around [Function Calling](https://platform.openai.com/docs/guides/function-calling?api-mode=responses) which took quite a while but in the end gave me a really good understanding of some other tools at my disposal with the expansive OpenAI API. Function calling is described on OpenAI's docs as follows:  

> You can give the model access to your own custom code through function calling. Based on the system prompt and messages, the model may decide to call these functions — instead of (or in addition to) generating text or audio.  
> 
> You'll then execute the function code, send back the results, and the model will incorporate them into its final response.  

I decided to build the JSON schema myself and used it in a function to extract the appropriate data out of the user input to put into the Spoonacular API query string format. It was a fantastic exercise in working with multiple documentation sources to come up with a solution but it took the bulk of my time to get everything lining up with the final API call query. 


**Lessons learned**  
I read a post somewhere recently where someone joked that "6 hours of debugging can save you 5 minutes of reading documentation". Getting AI to build the components and handle things like state and component structure gets you far in a short period of time, but sometimes it takes poring through documentation to discover the connections you need to make to understand what's possible. 


**Final thoughts**  
It's a daily struggle to get the balance of how much I rely on AI to do my building for me. There's time benefits in getting it to generate things quickly but how much time do you actually save if you have to spend the next hour poring through what it has built trying to understand how it has pieced everything together. As my AI instincts get honed further, I find myself giving it less free reign, being more precise with my prompts and limiting it's scope to smaller and smaller parts to build/debug, just so I can keep a good grasp on what's getting put into my own app.

This project has been built as part of my AI August App-A-Day Challenge. You can read more information on the full project here: [https://github.com/davedonnellydev/ai-august-2025-challenge](https://github.com/davedonnellydev/ai-august-2025-challenge).  

## 🧪 Testing

![CI](https://github.com/davedonnellydev/ai-august-2025-03/actions/workflows/npm_test.yml/badge.svg)  
*Note: Test suite runs automatically with each push/merge.*  

## Quick Start

1. **Clone and install:**
   ```bash
   git clone https://github.com/davedonnellydev/ai-august-2025-03.git
   cd ai-august-2025-03
   npm install
   ```

2. **Set up environment variables:**
   ```bash
   cp .env.example .env.local
   # Edit .env.local with your values
   ```

3. **Start development:**
   ```bash
   npm run dev
   ```

4. **Run tests:**
   ```bash
   npm test
   ```

## 🔧 Configuration

### Environment Variables

Create a `.env.local` file in the root directory:

```bash
# OpenAI API (for AI features)
OPENAI_API_KEY=your_openai_api_key_here

# Optional: External API URLs
USER_API_URL=https://jsonplaceholder.typicode.com/users
PRODUCT_API_URL=https://dummyjson.com/products

# Optional: Proxy Settings
ENABLE_CACHE=true
CACHE_DURATION=300000
```

### Key Configuration Files

- **`next.config.mjs`** - Next.js configuration with bundle analyzer
- **`tsconfig.json`** - TypeScript configuration with path aliases (`@/*`)
- **`theme.ts`** - Mantine theme customization
- **`eslint.config.mjs`** - ESLint rules with Mantine and TypeScript support
- **`jest.config.cjs`** - Jest testing configuration
- **`.nvmrc`** - Node.js version (v24.3.0)

### Path Aliases

The project uses TypeScript path aliases for cleaner imports:

```typescript
import { Component } from '@/components/Component';  // instead of '../../../components/Component'
```


## 📦 Available Scripts
### Build and dev scripts

- `npm run dev` – start dev server
- `npm run build` – bundle application for production
- `npm run analyze` – analyzes application bundle with [@next/bundle-analyzer](https://www.npmjs.com/package/@next/bundle-analyzer)

### Testing scripts

- `npm run typecheck` – checks TypeScript types
- `npm run lint` – runs ESLint
- `npm run prettier:check` – checks files with Prettier
- `npm run jest` – runs jest tests
- `npm run jest:watch` – starts jest watch
- `npm test` – runs `jest`, `prettier:check`, `lint` and `typecheck` scripts

### Other scripts

- `npm run storybook` – starts storybook dev server
- `npm run storybook:build` – build production storybook bundle to `storybook-static`
- `npm run prettier:write` – formats all files with Prettier


## 📜 License
![GitHub License](https://img.shields.io/github/license/davedonnellydev/ai-august-2025-03)  
This project is licensed under the MIT License.  
